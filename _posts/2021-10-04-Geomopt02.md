---
title: 'Part II: the Space of Natural-Gradients at one Point'
date: 2021-10-04
permalink: /posts/2021/10/Geomopt02/
tags:
  - Natural Gradient Descent
  - Information Geometry
  - Riemannian Manifold
---

Goal
------
This blog post should help readers to understand natural-gradients, which are known as Riemannian gradients with the Fisher-Rao metric.
The space of natural-gradients evaluated at the same point is called a tangent space at that point in a manifold. 


We will give an informal introduction with a focus on high level of ideas.

# Euclidean steepest direction and directional derivative
------
Before we discuss natural-gradients, we first revisit Euclidean gradients.
We will show a Euclidean gradient can be viewed as the steepest direction. Later, we extend the steepest direction in Riemannian cases and show that the steepest direction is indeed a natural-gradient.

Given a smooth scalar function $\min_{\tau \in \mathcal{R}^K } \,\,f(\mathbf{\tau})$ in a **vector space** `$\mathcal{R}^K$`, we can define the (Euclidean) steepest direction at current `$\mathbf{\tau}_0$` as the optimal solution to the following optimization problem. We can express the optimization problem in terms of a **directional derivative** along vector $\mathbf{v}$. We assume `$\nabla_\tau f(\mathbf{\tau}_0)  \neq \mathbf{0}$`.
`$$
\begin{aligned}
\min_{\|v\|^2=1} \lim_{t \to 0} \frac{f(\mathbf{\tau}_0+t\mathbf{v}) - f(\mathbf{\tau}_0) }{t} = ( \nabla_\tau f(\mathbf{\tau}_0) )^T \mathbf{v} 
\end{aligned}\tag{1}\label{1}
$$` 

It is easy to see that the optimal solution of Eq. `$\eqref{1}$` is `$\mathbf{v}_{\text{opt}}= -\frac{\nabla_\tau f(\mathbf{\tau}_0) }{\|\nabla_\tau f(\mathbf{\tau}_0) \|}$`, which is the (Euclidean) steepest direction at point `$\mathbf{\tau}_0$`.


# Distance induced by the Fisher-Rao metric 
------

To generalize  the steepest direction at point `$\mathbf{\tau}_0$` in a Riemannian manifold, we first formulate a similar optimization problem like Eq. `$\eqref{1}$` in the manifold case.
To do so, we have to define the length of a vector in manifold cases. In Part III, we will show that the (standard) length does not persever under a parameter transform while the length induced by the Fisher-Rao metric does.


As mentioned at [Part I]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#fisher-rao-metric), the FIM $\mathbf{F}$ should be positive definite. We can use FIM to define the length/norm of a vector (e.g., a Riemannian gradient) $\mathbf{v}$ at a point in a manifold via a weighted inner product.
`$$
\begin{aligned}
\|\mathbf{v}\|_F := \sqrt{\mathbf{v}^T \mathbf{F} \mathbf{v}}
\end{aligned}
$$`

The positive-definiteness of FIM is essential since we do not want a non-zero vector has a zero length.

The distance (and orthogonality) between two <span style="color:red">vectors at the same point</span> is also induced by FIM since we can define them by the inner product as
`$$
\begin{aligned}
d(\mathbf{v},\mathbf{w}) := \|\mathbf{v}-\mathbf{w}\|_F
\end{aligned}
$$`
where `$\mathbf{v}$` and `$\mathbf{w}$` are two vectors evaluted at point `$\tau_0$`.

In manifold cases, we have to distinguish the difference between a point (e.g., parameter $\tau_0$) and a vector (e.g., Riemannian gradient under a parametrization `$\tau$`).

**Warning**:  We do NOT define the distance between two points in the manifold, which will be discussed [here](#riemannian-gradients-as-tangent-vectors-optional).
We also do NOT define the distance between a vector at one point and another vector at a distinct point.

# Directional derivatives in a manifold
------
As we shown before, the objective function in Eq. `$\eqref{1}$` is a directional derivative in Euclidean cases.
The next step is to generalize the concept of directional derivatives in a manifold. 


Recall that a manifold should be locally like a vector space under [**intrinsic** parameterization]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations) `$\mathbf{\tau}$`.
Using this parameterization, consider an optimization problem $\min_{\tau \in \Omega_\tau } f(\mathbf{\tau})$, where the parameter space $\Omega_\tau$ is determined by the parameterization and the manifold. Recall that we have a local vector space structure denoted by $E$ if we parametrize the manifold with an intrinsic parameterization.

Therefore, we can similarly define a directional derivative at `$\mathbf{\tau}_0$` along Riemannian vector $\mathbf{v}$ as `$\lim_{t \to 0} \frac{f(\mathbf{\tau}_0+t\mathbf{v}) - f(\mathbf{\tau}_0) }{t}$`, where $t$ is a scalar real number. The main point is that `$\mathbf{\tau}_0+t\mathbf{v}$` stays in the parameter space `$\Omega_\tau$` thanks to the **local vector space** structure.


Recall that we allow a [small perturbation]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations) `$E$` contained in  parameter space  `$\Omega_\tau$` (i.e., `$E \subset \Omega_\tau$`) since  `$\mathbf{\tau}$` is an intrinsic parameterization.
Therefore, when $|t|$ is small enough, `$\mathbf{\tau}_0+t\mathbf{v} $` stays in the parameter space and `$f(\mathbf{\tau}_0+t\mathbf{v})$` is well-defined.
Note that we only require `$\mathbf{\tau}_0+t\mathbf{v} \in \Omega_\tau$` when $|t|$ is small enough. When $|t|$ is small enough, this is possible since a line segment `$ \mathbf{\tau}_0+t\mathbf{v} \in E$` and `$E \subset \Omega_\tau$`.
 Technically, this is because  $\Omega_\tau$ is an open set in $\mathcal{R}^K$, where $K$ is the number of (scalar) parameters. 


Under **intrinsic** parameterization $\mathbf{\tau}$, the directional derivative remains the same as in the Euclidean case.
`$\lim_{t \to 0} \frac{f(\mathbf{\tau}_0+t\mathbf{v}) - f(\mathbf{\tau}_0) }{t} = ( \nabla_\tau f(\mathbf{\tau}_0))^T \mathbf{v} $`. 

The following example illustrates a directional derivative in a manifold.

>Example 1:
>
>`$\tau$` is a **local intrinsic** parameterization for the unit sphere.
>  
>The line segment from `$\mathbf{\tau}_0$` to `$\mathbf{\tau}_0+t\mathbf{v} $`  is shown in blue, which is the parameter representation of the yellow curve `$\gamma(t)$` in the manifold.
>We will show later that Riemannian gradient vector `$\mathbf{v}$` under this parametrization at point `$\mathbf{\tau}_0$` is the **parameter representation** of the tangent vector of curve `$\gamma(t)$` at point `$\mathbf{x}_0$`.
>
><img src="/img/sphere_simple.png"  width="500"/>
>
>**Warning**: Curve `$\gamma(t)$` is not the shortest curve in the manifold between `$\mathbf{x}_0$` and `$\mathbf{x}_1$`. The shortest curve is not a straight line in curved manifold cases.



>Example 2:
>
>A directional derivative can be ill-defined under a **non-intrinsic** parameterization.
>
>We use [parameterization 3]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations) for unit circle `$\mathcal{S}^1$`, where the red line segment passes through `$\tau_0=(0,1) \in \mathcal{S}^1 $`.
>
>![Figure 1](/img/tangent_non.png) 
>
>Any other point `$\tau_0 + t\mathbf{v}$` in the line segment leaves the manifold for `$t>0$` and thus, `$f(\mathbf{\tau}_0+t\mathbf{v})$` is not well-defined.
>The main reason is that `$\tau$` is not an intrinsic parameterization.




# Riemannian steepest direction
------
Recall that we have defined the length of a Riemannian vector and directional derivatives in a manifold.
Now, we can introduce the Riemannian steepest direction.

Given  a smooth scalar funcion defined in a manifold $\min_{\tau \in \Omega_\tau } f(\mathbf{\tau})$ under an intrinsic parameterization $\mathbf{\tau}$. We can define the Riemannian steepest direction as the optimal solution to the following optimization problem.  The optimization problem is expressed in terms of a directional derivative along Riemannian vector $\mathbf{v}$, where we assume `$\nabla_\tau f(\mathbf{\tau}_0)  \neq \mathbf{0}$`.
`$$
\begin{aligned}
\min_{ \color{red} {\|v\|_{F}^2=1} } ( \nabla_\tau f(\mathbf{\tau}_0) )^T  \mathbf{v} 
\end{aligned} \tag{2}\label{2}
$$` 
where $\mathbf{v}$ can be any (Riemannian) vector at current point `$\mathbf{\tau}_0$` satisfied the norm constraint.

The Lagrangian function of this problem is given below, where $\lambda$ is a Lagrange multiplier. 
`$$
\begin{aligned}
L(\mathbf{v},\lambda) =  ( \nabla_\tau f(\mathbf{\tau}_0))^T \mathbf{v} + \lambda (\|v\|_{F}^2 - 1) = \mathbf{v}^T \nabla_\tau f(\mathbf{\tau}_0) + \lambda (\mathbf{v}^T \mathbf{F}(\mathbf{\tau}_0) \mathbf{v}  - 1) 
\end{aligned}
$$` where `$\mathbf{F}(\mathbf{\tau}_0)$` is FIM evaluated at point `$\tau_0$`.

One of the KKT necessary conditions implies that
`$$
\begin{aligned}
\mathbf{0} = \nabla_{v} L(\mathbf{v}_{\text{opt}},\lambda) = \nabla_\tau f(\mathbf{\tau}_0) + 2 \lambda \mathbf{F}(\mathbf{\tau}_0) \mathbf{v}_{\text{opt}}
\end{aligned}
$$`
When $\lambda \neq 0$, vector 	`$\mathbf{v}_{\text{opt}}$` should be proportional to `$\mathbf{F}^{-1}(\mathbf{\tau}_0) \nabla_\tau f(\mathbf{\tau}_0)$`, where  `$\mathbf{F}^{-1}(\mathbf{\tau}_0)$` is well-defined since FIM `$\mathbf{F}(\mathbf{\tau}_0)$` is positive definite.
 

We can show that the optimal solution of Eq. `$\eqref{2}$` is `$\mathbf{v}_{\text{opt}}= -\frac{ \mathbf{F}^{-1}(\mathbf{\tau}_0) \nabla_\tau f(\mathbf{\tau}_0) }{\| \mathbf{F}^{-1}(\mathbf{\tau}_0)\nabla_\tau f(\mathbf{\tau}_0) \|_F}$`, which gives us the Riemannian steepest direction at current `$\mathbf{\tau}_0$`. 

The **Euclidean** steepest direction `$\mathbf{v}_{\text{euclid}}= -\frac{ \nabla_\tau f(\mathbf{\tau}_0) }{\| \nabla_\tau f(\mathbf{\tau}_0) \|_F}$` is **not** the optimal solution of  Eq. `$\eqref{2}$` when `$\mathbf{F}(\tau_0) \neq \mathbf{I}$`.
We will illustrate this by using an example.

>Example
>
>Consider `$\mathbf{F}(\tau_0)=\begin{bmatrix} 1 & 0 \\ 0 & \frac{1}{2} \end{bmatrix}$` and `$\nabla_\tau f(\mathbf{\tau}_0)=\begin{bmatrix} 1\\1 \end{bmatrix}$`.
>We have the following results
> `$$
\begin{aligned}
\| F^{-1} \nabla_\tau f(\mathbf{\tau}_0) \|_F^2  =  \nabla_\tau^T f(\mathbf{\tau}_0) \mathbf{F}^{-1}(\tau_0) \nabla_\tau f(\mathbf{\tau}_0) = 3; \,\,\,
\| \nabla_\tau f(\mathbf{\tau}_0) \|_F^2  =  \nabla_\tau^T f(\mathbf{\tau}_0) \mathbf{F}(\tau_0) \nabla_\tau f(\mathbf{\tau}_0) = \frac{3}{2}
\end{aligned}
$$`
> `$$
\begin{aligned}
\mathbf{v}_{\text{opt}} = -\begin{bmatrix} \frac{1}{\sqrt{3}} \\ \frac{2}{\sqrt{3}} \end{bmatrix}; \,\,\,
\mathbf{v}_{\text{euclid}}=
-\begin{bmatrix} \sqrt{\frac{2}{3}} \\ \sqrt{\frac{2}{3}} \end{bmatrix}\end{aligned}
$$`
>`$$
\begin{aligned}
 \mathbf{v}_{\text{opt}}^T \nabla_\tau f(\mathbf{\tau}_0)= -\sqrt{3}  <  -\frac{2\sqrt{2}}{\sqrt{3}} = \mathbf{v}_{\text{euclid}}^T \nabla_\tau f(\mathbf{\tau}_0) 
\end{aligned}
$$`
>
>Therefore, the Euclidean steepest direction `$\mathbf{v}_{\text{euclid}}$` is not the optimal solution of  Eq. `$\eqref{2}$`.


Given a scalar function $f(\mathbf{\tau})$, if its **Euclidean** (steepest) gradient is $\nabla_\tau f(\mathbf{\tau})$, its **Riemannian** (steepest) gradient is defined as $ \mathbf{F}^{-1}(\mathbf{\tau}) \nabla_\tau f(\mathbf{\tau})$ in literature.
We use a learning-rate to control the length of a gradient instead of normalizing its length. 
Since we use the Fisher-Rao metric, the Riemannian gradient is also known as the **natural** gradient.



 
> Intrinsic parametrization and natural-gradients for multivate Gaussian
>
>Consider a $d$-dimensional Gaussian family with zero mean discussed in [Part I]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#manifold-dimension). <br />
>We specify an intrinsic parameterization $\mathbf{\tau}$ of the  family as `$ \{ \mathcal{N}(\mathbf{w} |\mathbf{0},\mathbf{\Sigma}) \Big| \mathrm{MatH}(\tau) = \mathbf{\Sigma}   \succ \mathbf{0} \}$` with `$\tau = \mathrm{vech}(\mathbf{\Sigma})$`, where `$\tau$` is a $\frac{d(d+1)}{2}$-dim vector and map $\mathrm{MatH}()$ is the inverse map of the the half-vectorization function $\mathrm{vech}()$. 
>
>Technically speaking, `$\mathbf{\Sigma}$` is NOT an intrinsic parameter due to the symmetry constraint. In other words, FIM w.r.t. `$\mathbf{\Sigma}$` will be singular if  `$\mathbf{\Sigma}$` is considered as a matrix parameter with $d^2$ degrees of freedom.
>
>In literature, a natural gradient w.r.t. `$\mathbf{\Sigma}$` is defined as `$\mathrm{MatH}(\mathbf{v})$`, where `$\mathbf{v}$` is a natural-gradient w.r.t. `$\mathrm{vech}(\mathbf{\Sigma})$`. 
 





# Riemannian gradients as tangent vectors (optional)
------
In the previous section, we only consider Riemannian vectors/gradients under a parametrization $\tau$.
Now, we will disucss a more abstract concept of Riemannian vectors without a parametrization. This concept is often used to show the invariance of Riemannian gradients, which will be discussed in Part III.  In physics, this invariance means that a law of physics should be independent of the choice of coordinate systems.

A Riemannian gradient denoted by $\mathbf{v}(\tau)$ is indeed a tangent vector $\mathbf{v}$  in the manifold under the parametrization $\tau$. 
The set of tangent vectors evaluated at $\mathbf{\tau}_0$ is called the tangent space at the corresponding point. 
We will illustrate this by an example.


Let's denote the unit sphere by $\mathcal{M}$, where we set the origin to be the center of the sphere. Point $\mathbf{x_0}=(0,0,1)$ is the north pole.
We use the following parameterization, where the top half of the sphere can be locally expressed as `$\{(\tau_x,\tau_y,\sqrt{1-\tau_x^2-\tau_y^2})|  \tau_x^2 + \tau_y^2 <1 \}$` with parameter $\mathbf{\tau}=(\tau_x,\tau_y)$. 
Under parametrization $\mathbf{\tau}$, we have the following parametric representations.  

|   &nbsp; &nbsp; &nbsp;    | Parametric representation     | 
|:------------|:-------------:|
| North pole  $\mathbf{x_0}$   | $\mathbf{\tau}_0=(0,0)$  |  
| Intrinsic parameter space     |  red space `$\Omega_\tau:=\{ (\tau_x,\tau_y)| \tau_x^2 + \tau_y^2 <1 \}$`   |
| Tangent space at $\mathbf{x_0}$     |  green space  `$\mathcal{R}^2$` at `$\mathbf{\tau}_0$`   |
| Yellow curve from $\mathbf{x_0}$ to $\mathbf{x_1}$    |  blue line segment from `$\mathbf{\tau}_0$` to `$\mathbf{\tau}_0+t\mathbf{v}(\tau_0)$`   |  



<img src="/img/sphere.png"  width="500"/>

**Warning**: Be aware of the differences shown in the table.

|   &nbsp; &nbsp; &nbsp;    |   parametric representation of   |     supported operations   |      distance  discussed in this post  |
|:------------|:-------------:|:-------------:|
|  `$\mathcal{R}^2$` (vector/natural-gradient) space |   tangent vector space at `$\mathbf{x}_0$`  | real scalar product, vector addition  | defined |
|   `$\Omega_\tau$` (point/parameter) space | top half of the manifold  |   **local**  scalar product, **local** vector addition   |  undefined |

Under **intrinsic** parametrization $\tau$, we have `$\Omega_\tau \subset \mathcal{R}^2$`. Thus, we can perform the operation in $\Omega_\tau$ space: `$\tau_0 +t\mathbf{v}(\tau_0) \in \Omega_\tau$` when scalar `$|t|$` is small enough. Note that we only define the [distance](#distance-induced-by-the-fisher-rao-metric) between two vectors in the `$\mathcal{R}^2$` space. The distance between two points in the `$\Omega_\tau$` space is undefined.



The tangent vector $\mathbf{v}$ at point $\mathbf{x_0}$  can be viewed as the **tangent direction** of a (1-dimensional) smooth curve $\gamma(t) \in \mathcal{M}$, where $\gamma(0)=\mathbf{x_0}$,  `$\frac{d {\gamma}(t) }{d t} \Big|_{t=0}=\mathbf{v}$` and the support of $t$ is an open interval containing 0. 
Given parametrization $\tau$, we can define the parametric representation of the curve denoted by ${\gamma}_\tau(t)$. 
The parametric representation of vector `$\mathbf{v}$` is defined as `$\mathbf{v}(\mathbf{\tau}_0):= \frac{d {\gamma}_{\tau}(t) }{d t} \Big|_{t=0}$`, where `${\gamma}_{\tau}(0)=\tau_0$`. 
We can also define vector additions and real scalar products by using tangent directions of curves in the manifold. 

>Example
>
>Consider the yellow curve $\gamma(t) = (t v_{x}, t v_{y}, \sqrt{1 - t^2(v_{x}^2 + v_{y}^2) } ) \in \mathcal{M} $ 
>and the blue line segment `${\gamma}_{\tau}(t)= (t v_{x} , t v_y  ) \in \Omega_\tau $`, where `$|t|$` must be small enough. 
>
>The parametric  representation of the vector is `$\mathbf{v}(\mathbf{\tau}_0):= \frac{d {\gamma}_\tau(t) }{d t} \Big|_{t=0}=(v_x,v_y)$`.

The parametric  representation of the tangent vector can also be derived from directional derivatives as shown below.

>
>Consider a smooth scalar function defined in the manifold $h: \mathcal{M} \to \mathcal{R}$. In the unit sphere case, consider `$h(\mathbf{x})$` subject to `$\mathbf{x}^T \mathbf{x}=1$`.
>Under parameterization $\mathbf{\tau}$, we can locally re-expressed the function as `$h_\tau(\mathbf{\tau}):=h( (\tau_x,\tau_y,\sqrt{1-\tau_x^2-\tau_y^2}) )$` where `$\tau \in \Omega_\tau$`.
>
>By the definition of a directional derivative, the following identity holds for any smooth scalar function $h$: `$[\nabla h_\tau(\mathbf{\tau}_0)]^T \mathbf{v}(\mathbf{\tau}_0) =\frac{d h_\tau({\gamma}_\tau(t)) }{d t} \Big|_{t=0}$`, where $h_\tau$ is the parametric representation of  $h$ . Note that `$(h_\tau \circ {\gamma}_\tau) (t)$` is a function defined from $\mathcal{R}^1$ to $\mathcal{R}^1$.
>By the chain rule, we have `$\frac{d h_\tau({\gamma}_\tau(t)) }{d t} \Big|_{t=0}=[\nabla h_\tau(\mathbf{\tau}_0)]^T  \frac{d {\gamma}_\tau(t) }{d t} \Big|_{t=0}$`, where `${\gamma}_\tau(0)=\tau_0$`. Thus,
> `$\mathbf{v}(\mathbf{\tau}_0) =  \frac{d {\gamma}_\tau(t) }{d t} \Big|_{t=0}$` since `$\nabla h_\tau(\mathbf{\tau}_0)$` can be arbitrary.
>
>In summary, a Riemannian gradient `$\mathbf{v}(\mathbf{\tau}_0)$` can be viewed as a parametric representation of the tangent vector of curve $\gamma(t)$ at $\mathbf{x}_0$ since  `${\gamma}_\tau(t)$` is the parametric representation of $\gamma(t)$.
 




 
