---
title: 'Part II: Natural-Gradients Evaluted at one Point'
date: 2021-10-04
permalink: /posts/2021/10/Geomopt02/
tags:
  - Natural Gradient Descent
  - Information Geometry
  - Riemannian Manifold
---

Goal
------
This blog post should help readers to understand natural-gradients, which are known as Riemannian gradients with the Fisher-Rao metric.
The main propose of this post is to show how to compute/define a natural-gradient.
The space of natural-gradients evaluated at the same point is called a tangent space at that point. 



We will give an informal introduction with a focus on high level of ideas.



# Euclidean steepest direction and directional derivative
------
Before we discuss natural-gradients, we first revisit Euclidean gradients.
 
We will show a Euclidean gradient can be viewed as the Euclidean steepest direction. Later, we extend the steepest direction in Riemannian cases and show that the Riemannian steepest direction w.r.t. the Fisher-Rao metric is indeed a natural-gradient.

Given a smooth scalar function $\min_{\tau \in \mathcal{R}^K } \,\,f(\mathbf{\tau})$ in a **vector space** `$\mathcal{R}^K$`, we can define the (Euclidean) steepest direction at current `$\mathbf{\tau}_0$` as the optimal solution to the following optimization problem. We can express the optimization problem in terms of a **directional derivative** along vector $\mathbf{v}$. We assume `$\nabla_\tau f(\mathbf{\tau}_0)  \neq \mathbf{0}$`.
`$$
\begin{aligned}
\min_{\|v\|^2=1} \lim_{t \to 0} \frac{f(\mathbf{\tau}_0+t\mathbf{v}) - f(\mathbf{\tau}_0) }{t} = ( \nabla_\tau f(\mathbf{\tau}_0) )^T \mathbf{v} 
\end{aligned}\tag{1}\label{1}
$$` 

It is easy to see that the optimal solution of Eq. `$\eqref{1}$` is `$\mathbf{v}_{\text{opt}}= -\frac{\nabla_\tau f(\mathbf{\tau}_0) }{\|\nabla_\tau f(\mathbf{\tau}_0) \|}$`, which is the (Euclidean) steepest direction at point `$\mathbf{\tau}_0$`.


# Distance induced by the Fisher-Rao metric 
------

To generalize  the steepest direction at point `$\mathbf{\tau}_0$` in a Riemannian manifold, we first formulate a similar optimization problem like Eq. `$\eqref{1}$` in the manifold case.
To do so, we have to define the length of a vector in manifold cases. In [Part III]({{ site.baseurl }}{% post_url 2021-11-02-Geomopt03 %}#standard-euclidean-gradients-are-not-invariant), we will show that the (standard) length does not perseve under a parameter transform while the length induced by the Fisher-Rao metric does.


As mentioned at [Part I]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#fisher-rao-metric), the FIM $\mathbf{F}$ should be positive definite. We can use FIM to define the length/norm of a vector (e.g., a Riemannian gradient) $\mathbf{v}$ at a point in a manifold via a weighted inner product.
`$$
\begin{aligned}
\|\mathbf{v}\|_F := \sqrt{\mathbf{v}^T \mathbf{F} \mathbf{v}}
\end{aligned}
$$`

The positive-definiteness of FIM is essential since we do not want a non-zero vector has a zero length.

The distance (and orthogonality) between two <span style="color:red">vectors</span> at the <span style="color:red">same</span>  point is also induced by FIM since we can define them by the inner product as
`$$
\begin{aligned}
d(\mathbf{v},\mathbf{w}) := \|\mathbf{v}-\mathbf{w}\|_F
\end{aligned}
$$`
where `$\mathbf{v}$` and `$\mathbf{w}$` are two vectors evaluted at point `$\tau_0$`.

In manifold cases, we have to distinguish the difference between a point (e.g., parameter array $\tau_0$) and a vector (e.g., Riemannian gradient under a parametrization `$\tau$`).
This point is crucial to (natural) gradient-based methods in [Part IV]({{ site.baseurl }}{% post_url 2021-11-15-Geomopt04 %}#two-kinds-of-spaces).


<span style="color:red">**Warning**</span>: We do NOT define the distance between two points in the manifold, which will be discussed [here](#riemannian-gradients-as-tangent-vectors-optional).
We also do NOT define the distance between a vector at one point and another vector at a distinct point.

# Directional derivatives in a manifold
------
As we shown before, the objective function in Eq. `$\eqref{1}$` is a directional derivative in Euclidean cases.
The next step is to generalize the concept of directional derivatives in a manifold. 


Recall that a manifold should be locally like a vector space under [**intrinsic** parameterization]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations) `$\mathbf{\tau}$`.
Using this parameterization, consider an optimization problem $\min_{\tau \in \Omega_\tau } f(\mathbf{\tau})$, where the parameter space $\Omega_\tau$ is determined by the parameterization and the manifold. Recall that we have a local vector space structure denoted by $E$ if we parametrize the manifold with an intrinsic parameterization.

Therefore, we can similarly define a directional derivative at `$\mathbf{\tau}_0$` along Riemannian vector $\mathbf{v}$ as `$\lim_{t \to 0} \frac{f(\mathbf{\tau}_0+t\mathbf{v}) - f(\mathbf{\tau}_0) }{t}$`, where $t$ is a scalar real number. The main point is that `$\mathbf{\tau}_0+t\mathbf{v}$` stays in the parameter space `$\Omega_\tau$` thanks to the **local vector space** structure.


Recall that we allow a [small perturbation]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations) `$E$` contained in  parameter space  `$\Omega_\tau$` (i.e., `$E \subset \Omega_\tau$`) since  `$\mathbf{\tau}$` is an intrinsic parameterization.
Therefore, when $|t|$ is small enough, `$\mathbf{\tau}_0+t\mathbf{v} $` stays in the parameter space and `$f(\mathbf{\tau}_0+t\mathbf{v})$` is well-defined.
Note that we only require `$\mathbf{\tau}_0+t\mathbf{v} \in \Omega_\tau$` when $|t|$ is small enough. When $|t|$ is small enough, this is possible since a line segment `$ \mathbf{\tau}_0+t\mathbf{v} \in E$` and `$E \subset \Omega_\tau$`.
 Technically, this is because  $\Omega_\tau$ is an open set in $\mathcal{R}^K$, where $K$ is the number of entires of parameter array `$\tau$`. 


Under **intrinsic** parameterization $\mathbf{\tau}$, the directional derivative remains the same as in the Euclidean case thanks to the **local vector space** structure.
`$$\begin{aligned} \lim_{t \to 0} \frac{f(\mathbf{\tau}_0+t\mathbf{v}) - f(\mathbf{\tau}_0) }{t} = ( \nabla_\tau f(\mathbf{\tau}_0))^T \mathbf{v} \end{aligned}$$`. 

The following example illustrates directional derivatives in manifold cases.

<details>
<summary>Valid case:</summary>
<fieldset class="field-set" markdown="1">
>
>`$\tau$` is a **local intrinsic** parameterization for the unit sphere.
>  
>The line segment from `$\mathbf{\tau}_0$` to `$\mathbf{\tau}_0+t\mathbf{v} $`  is shown in blue, which is the parameter representation of the yellow curve `$\gamma(t)$` in the manifold.
>We will show later that Riemannian gradient vector `$\mathbf{v}$` under this parametrization at point `$\mathbf{\tau}_0$` is the **parameter representation** of the tangent vector of curve `$\gamma(t)$` at point `$\mathbf{x}_0$`.
>
><img src="/img/sphere_simple.png"  width="500"/>
>
>**Warning**: Curve `$\gamma(t)$` is NOT the shortest curve in the manifold between `$\mathbf{x}_0$` and `$\mathbf{x}_1$`. 
</fieldset>
</details>


<details>
<summary>Invalid case:</summary>
<fieldset class="field-set" markdown="1">
>
>A directional derivative can be ill-defined under a **non-intrinsic** parameterization.
>
>We use [parameterization 3]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations) for unit circle `$\mathcal{S}^1$`, where the red line segment passes through `$\tau_0=(0,1) \in \mathcal{S}^1 $`.
>
>![Figure 1](/img/tangent_non.png) 
>
>Any other point `$\tau_0 + t\mathbf{v}$` in the line segment leaves the manifold for `$t\neq 0$` and thus, `$f(\mathbf{\tau}_0+t\mathbf{v})$` is not well-defined.
>The main reason is that `$\tau$` is not an intrinsic parameterization.
</fieldset>
</details>




# Riemannian steepest direction
------
Recall that we have defined the length of a Riemannian vector and directional derivatives in a manifold.
Now, we can introduce the Riemannian steepest direction. We will use this to define/compute natrual-gradients.

Given  a smooth scalar funcion defined in a manifold $\min_{\tau \in \Omega_\tau } f(\mathbf{\tau})$ under an intrinsic parameterization $\mathbf{\tau}$. We can define the Riemannian steepest direction as the optimal solution to the following optimization problem.  The optimization problem is expressed in terms of a directional derivative along Riemannian vector $\mathbf{v}$, where we assume `$\nabla_\tau f(\mathbf{\tau}_0)  \neq \mathbf{0}$`.
`$$
\begin{aligned}
\min_{ \color{red} {\|v\|_{F}^2=1} } ( \nabla_\tau f(\mathbf{\tau}_0) )^T  \mathbf{v} 
\end{aligned} \tag{2}\label{2}
$$` 
where $\mathbf{v}$ can be any (Riemannian) vector at current point `$\mathbf{\tau}_0$` satisfied the norm constraint.

The Lagrangian function of this problem is given below, where $\lambda$ is a Lagrange multiplier. 
`$$
\begin{aligned}
L(\mathbf{v},\lambda) =  ( \nabla_\tau f(\mathbf{\tau}_0))^T \mathbf{v} + \lambda (\|v\|_{F}^2 - 1) = \mathbf{v}^T \nabla_\tau f(\mathbf{\tau}_0) + \lambda (\mathbf{v}^T \mathbf{F}(\mathbf{\tau}_0) \mathbf{v}  - 1) 
\end{aligned}
$$` where `$\mathbf{F}(\mathbf{\tau}_0)$` is FIM evaluated at point `$\tau_0$`.

One of the Karush–Kuhn–Tucker (KKT) necessary conditions implies that
`$$
\begin{aligned}
\mathbf{0} = \nabla_{v} L(\mathbf{v}_{\text{opt}},\lambda) = \nabla_\tau f(\mathbf{\tau}_0) + 2 \lambda \mathbf{F}(\mathbf{\tau}_0) \mathbf{v}_{\text{opt}}
\end{aligned}
$$`
When $\lambda \neq 0$, vector 	`$\mathbf{v}_{\text{opt}}$` should be proportional to `$\mathbf{F}^{-1}(\mathbf{\tau}_0) \nabla_\tau f(\mathbf{\tau}_0)$`, where  `$\mathbf{F}^{-1}(\mathbf{\tau}_0)$` is well-defined since FIM `$\mathbf{F}(\mathbf{\tau}_0)$` is positive definite.
 

We can show that the optimal solution of Eq. `$\eqref{2}$` is `$\mathbf{v}_{\text{opt}}= -\frac{ \mathbf{F}^{-1}(\mathbf{\tau}_0) \nabla_\tau f(\mathbf{\tau}_0) }{\| \mathbf{F}^{-1}(\mathbf{\tau}_0)\nabla_\tau f(\mathbf{\tau}_0) \|_F}$`, which gives us the Riemannian steepest direction at current `$\mathbf{\tau}_0$`. 

The **Euclidean** steepest direction `$\mathbf{v}_{\text{euclid}}= -\frac{ \nabla_\tau f(\mathbf{\tau}_0) }{\| \nabla_\tau f(\mathbf{\tau}_0) \|_F}$` is **not** the optimal solution of  Eq. `$\eqref{2}$` when `$\mathbf{F}(\tau_0) \neq \mathbf{I}$`.
We will illustrate this by using an example.

<details>
<summary>Euclidean steepest direction is not the optimal solution of  Eq. $\eqref{2}$</summary>
<fieldset class="field-set" markdown="1">
>
>Consider `$\mathbf{F}(\tau_0)=\begin{bmatrix} 1 & 0 \\ 0 & \frac{1}{2} \end{bmatrix}$` and `$\nabla_\tau f(\mathbf{\tau}_0)=\begin{bmatrix} 1\\1 \end{bmatrix}$`.
>We have the following results
>`$$
>\begin{aligned}
>\| F^{-1} \nabla_\tau f(\mathbf{\tau}_0) \|_F^2  =  \nabla_\tau^T f(\mathbf{\tau}_0) \mathbf{F}^{-1}(\tau_0) \nabla_\tau f(\mathbf{\tau}_0) = 3; \,\,\,
>\| \nabla_\tau f(\mathbf{\tau}_0) \|_F^2  =  \nabla_\tau^T f(\mathbf{\tau}_0) \mathbf{F}(\tau_0) \nabla_\tau f(\mathbf{\tau}_0) = \frac{3}{2}
>\end{aligned}
>$$`
>
>`$$
>\begin{aligned}
>\mathbf{v}_{\text{opt}} = -\begin{bmatrix} \frac{1}{\sqrt{3}} \\ \frac{2}{\sqrt{3}} \end{bmatrix}; \,\,\,
>\mathbf{v}_{\text{euclid}}=
>-\begin{bmatrix} \sqrt{\frac{2}{3}} \\ \sqrt{\frac{2}{3}} \end{bmatrix}\end{aligned}
>$$`
>
>`$$
>\begin{aligned}
> \mathbf{v}_{\text{opt}}^T \nabla_\tau f(\mathbf{\tau}_0)= -\sqrt{3}  <  -\frac{2\sqrt{2}}{\sqrt{3}} = \mathbf{v}_{\text{euclid}}^T \nabla_\tau f(\mathbf{\tau}_0) 
>\end{aligned}
>$$`
>
>Therefore, the Euclidean steepest direction `$\mathbf{v}_{\text{euclid}}$` is not the optimal solution of  Eq. `$\eqref{2}$`.
</fieldset>
</details>

Given a scalar function $f(\mathbf{\tau})$, if its **Euclidean** (steepest) gradient is $\nabla_\tau f(\mathbf{\tau})$, its **Riemannian** (steepest) gradient is defined as $ \mathbf{F}^{-1}(\mathbf{\tau}) \nabla_\tau f(\mathbf{\tau})$ in literature.
We use a learning-rate to control the length of a gradient instead of normalizing its length. 
Since we use the Fisher-Rao metric, the Riemannian gradient is also known as the **natural** gradient.

 
<details>
<summary>Example: multivariate Gaussian</summary>
<fieldset class="field-set" markdown="1">
>
>Consider a $d$-dimensional Gaussian family with zero mean and precision `$\mathbf{S}$` discussed in [Part I]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#manifold-dimension). <br />
>We specify an intrinsic parameterization $\mathbf{\tau}$ of the family as `$ \{ \mathcal{N}(\mathbf{w} |\mathbf{0},\mathbf{S}^{-1}) \Big| \mathrm{MatH}(\tau) = \mathbf{S}   \succ \mathbf{0} \}$` with parametrization `$\tau = \mathrm{vech}(\mathbf{S})$`, where `$\tau$` is a $\frac{d(d+1)}{2}$-dim array and map $\mathrm{MatH}()$ is the inverse map of  the [half-vectorization function](https://en.wikipedia.org/wiki/Vectorization_(mathematics)#Half-vectorization) $\mathrm{vech}()$. 
>
>Technically speaking, `$\mathbf{S}$` is NOT an intrinsic parameter due to the symmetry constraint. In other words, FIM w.r.t. `$\mathbf{S}$` will be singular if  `$\mathbf{S}$` is considered as a matrix parameter with $d^2$ degrees of freedom.
>
>In the literature, a natural gradient w.r.t. `$\mathbf{S}$` is defined as `$\mathrm{MatH}(\mathbf{v})$`, where `$\mathbf{v}$` is a natural-gradient w.r.t. `$\mathrm{vech}(\mathbf{S})$`. 
</fieldset>
</details>





# Riemannian gradients as tangent vectors (optional)
------
In the previous section, we only consider Riemannian vectors/gradients under a parametrization $\tau$.
Now, we will disucss a more abstract concept of Riemannian vectors without a parametrization. This concept is often used to show the invariance of Riemannian gradients, which will be discussed in [Part III]({{ site.baseurl }}{% post_url 2021-11-02-Geomopt03 %}#parameter-transform-and-invariance).  In physics, this invariance means that a law of physics should be independent of the choice of (reference) coordinate systems.

A Riemannian gradient denoted by $\mathbf{v}(\tau)$ is indeed a tangent vector $\mathbf{v}$ of a smooth curve in the manifold under the parametrization $\tau$. 
The set of tangent vectors evaluated at $\mathbf{\tau}_0$ is called the tangent space at the corresponding point. 
We will illustrate this by an example.


Let's denote the unit sphere by $\mathcal{M}$, where we set the origin to be the center of the sphere. Point $\mathbf{x_0}=(0,0,1)$ is the north pole.
We use the following parameterization, where the top half of the sphere can be locally expressed as `$\{(\tau_x,\tau_y,\sqrt{1-\tau_x^2-\tau_y^2})|  \tau_x^2 + \tau_y^2 <1 \}$` with parameter $\mathbf{\tau}=(\tau_x,\tau_y)$. 
Under parametrization $\mathbf{\tau}$, we have the following parametric representations.  


|   &nbsp; &nbsp; &nbsp;    | Parametric representation     | 
|:------------|:-------------:|
| North pole  $\mathbf{x_0}$   | $\mathbf{\tau}_0=(0,0)$  |  
| Intrinsic parameter space     |  red space `$\Omega_\tau:=\{ (\tau_x,\tau_y)| \tau_x^2 + \tau_y^2 <1 \}$`   |
| Tangent space at $\mathbf{x_0}$     |  green space  `$\mathcal{R}^2$` at `$\mathbf{\tau}_0$`   |
| Yellow curve from $\mathbf{x_0}$ to $\mathbf{x_1}$    |  blue line segment from `$\mathbf{\tau}_0$` to `$\mathbf{\tau}_0+t\mathbf{v}(\tau_0)$`   |  




<img src="/img/sphere.png"  width="500"/>

Note that  `$\tau_0$` is a parameter array, which is a representation of a point $\mathbf{x}_0$ while $\mathbf{v}(\tau_0)$ is  a Riemannian gradient, which is a representation of the tangent vector of curve `$\gamma$` at point $\mathbf{x}_0$.



**Warning**: Be aware of the differences shown in the table.

|   &nbsp; &nbsp; &nbsp;    |   parametric representation of   |     supported operations   |      distance  discussed in this post  |
|:------------|:-------------:|:-------------:|
|  `$\mathcal{R}^2$` (vector/natural-gradient) space |   tangent vector space at `$\mathbf{x}_0$`  | real scalar product, vector addition  | defined |
|   `$\Omega_\tau$` (point/parameter) space | top half of the manifold  |  <span style="color:red"> **local** </span> scalar product, <span style="color:red">**local** </span> vector addition   |  undefined |

Under **intrinsic** parametrization $\tau$, we have `$\Omega_\tau \subset \mathcal{R}^2$`. Thus, we can perform this operation in $\Omega_\tau$ space: `$\tau_0 +t\mathbf{v}(\tau_0) \in \Omega_\tau$` when scalar `$|t|$` is small enough. Note that we only define the [distance](#distance-induced-by-the-fisher-rao-metric) between two vectors in the `$\mathcal{R}^2$` space. The distance between two points in the `$\Omega_\tau$` space is undefined in this post. 

## Parameterization-free repesentation of  vector $\mathbf{v}$

The tangent vector $\mathbf{v}$ at point $\mathbf{x_0}$  can be viewed as the **tangent direction** of a (1-dimensional) smooth curve $\gamma(t) \in \mathcal{M}$, where $\gamma(0)=\mathbf{x_0}$,  `$\frac{d {\gamma}(t) }{d t} \Big|_{t=0}=\mathbf{v}$` and the support of $\gamma(t)$ denoted by $\mathbf{I}$ is an open interval in  `$\mathcal{R}^1$` containing 0. 
Since a curve $\gamma(t)$ is a geometric object, this is a parameterization-free repesentation of a vector. 

## Parameterization-dependent repesentation of vector $\mathbf{v}$

Given intrinsic parametrization $\tau$, we can define the parametric representation of the curve denoted by ${\gamma}_\tau(t)$, where the domain is `$\mathbf{I}_\tau \subset \mathcal{R}^1$`.
The parametric representation of vector `$\mathbf{v}$` is defined as `$\mathbf{v}(\mathbf{\tau}_0):= \frac{d {\gamma}_{\tau}(t) }{d t} \Big|_{t=0}$`, where `${\gamma}_{\tau}(0)=\tau_0$`. 

>Example
>
>Consider the yellow curve $\gamma(t) = (t v_{x}, t v_{y}, \sqrt{1 - t^2(v_{x}^2 + v_{y}^2) } ) \in \mathcal{M} $ 
>and the blue line segment `${\gamma}_{\tau}(t)= (t v_{x} , t v_y  ) \in \Omega_\tau $`, where `$|t|$` must be small enough. 
>
>The parametric  representation of the vector is `$\mathbf{v}(\mathbf{\tau}_0):= \frac{d {\gamma}_\tau(t) }{d t} \Big|_{t=0}=(v_x,v_y)$`.

A Riemannian gradient `$\mathbf{v}(\mathbf{\tau}_0)$` can be viewed as a parametric representation of tangent vector  $\mathbf{v}$ as shown below.

>
>Consider a smooth scalar function defined in the manifold $h: \mathcal{M} \to \mathcal{R}$. In the unit sphere case, consider `$h(\mathbf{x})$` subject to `$\mathbf{x}^T \mathbf{x}=1$`.
>Under parameterization $\mathbf{\tau}$, we can locally re-expressed the function as `$h_\tau(\mathbf{\tau}):=h( (\tau_x,\tau_y,\sqrt{1-\tau_x^2-\tau_y^2}) )$` where `$\tau \in \Omega_\tau$`.
>
>By the definition of a directional derivative, the following identity holds for any smooth scalar function $h$: `$[\nabla h_\tau(\mathbf{\tau}_0)]^T \mathbf{v}(\mathbf{\tau}_0) =\frac{d h_\tau({\gamma}_\tau(t)) }{d t} \Big|_{t=0}$`, where $h_\tau$ is the parametric representation of  $h$ . Note that `$(h_\tau \circ {\gamma}_\tau) (t)$` is a function defined from `$\mathbf{I}_\tau $` to $\mathcal{R}^1$, where domain `$\mathbf{I}_\tau \subset \mathcal{R}^1$`.
>
> The <span style="color:red"> **key** </span> observation is that function `$(h_\tau \circ {\gamma}_\tau) (t)$` becomes a scalar function defined in $\mathcal{R}^1$ thanks to parametrization $\tau$. Thus, we can use the standard chain rule.
>
>By the chain rule, we have `$\frac{d h_\tau({\gamma}_\tau(t)) }{d t} \Big|_{t=0}=[\nabla h_\tau(\mathbf{\tau}_0)]^T  \frac{d {\gamma}_\tau(t) }{d t} \Big|_{t=0}$`, where `${\gamma}_\tau(0)=\tau_0$`. Thus,
> `$\mathbf{v}(\mathbf{\tau}_0) =  \frac{d {\gamma}_\tau(t) }{d t} \Big|_{t=0}$` since `$\nabla h_\tau(\mathbf{\tau}_0)$` can be arbitrary.
>
>In summary, a Riemannian gradient `$\mathbf{v}(\mathbf{\tau}_0)$` can be viewed as a parametric representation of the tangent vector 
 of curve $\gamma(t)$ at $\mathbf{x}_0$ since  `${\gamma}_\tau(t)$` is the parametric representation of $\gamma(t)$.
 
## (Riemannian) gradient space has a vector-space structure

We can also define vector additions and real scalar products in a tangent vector space by using tangent directions of curves in the manifold with/without a parameterization.

The key takeway is that a vector space structure is an integral part of a tangent **vector** space. On the other hand, we have to use an intrinsic parametrization $\tau$ to artificially create a local vector space structure in parameter space `$\Omega_\tau$`. Recall that a parameter space is a parametric representation of a set of **points** in a manifold.
We will discuss more about this in [Part IV]({{ site.baseurl }}{% post_url 2021-11-15-Geomopt04 %}#two-kinds-of-spaces)
