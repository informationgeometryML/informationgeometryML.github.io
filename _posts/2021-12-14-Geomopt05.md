---
title: 'Part V: Efficient Natural-gradient Methods for Exponential Family'
date: 2021-12-14
permalink: /posts/2021/12/Geomopt05/
tags:
  - Natural Gradient Descent
  - Information Geometry
  - Riemannian Manifold
  - Exponential Family
---

Warning: working in Progress (incomplete)

Goal
------
This blog post should show that we can efficiently implement natural-gradient methods in many cases.

We will give an informal introduction with a focus on high level of ideas.


# Exponential Family
------

An expoential family takes the following (canonical) form as
`$$
\begin{aligned}
p(\mathbf{w}|\mathbf{\eta}) = h_\eta(\mathbf{w}) \exp( \langle \mathbf{\eta} , \mathbf{T}_\eta (\mathbf{w}) \rangle - A_\eta (\mathbf{\eta}) )
\end{aligned}
$$` where the support of `$\mathbf{w}$` does not depend on `$\eta$`,  `$C_\eta(\eta) :=  \int h_\eta(\mathbf{w}) \exp( \langle \mathbf{\eta} , \mathbf{T}(\mathbf{w}) \rangle ) d \mathbf{w}
$` is the normalization constant.   `$A_\eta(\mathbf{\eta}):=\log C_\eta(\eta)$`,  `$h_\eta(\mathbf{w})$`, `$\mathbf{T}_\eta(\mathbf{w})$`, and `$\eta$`  are known as the log-partition function, the base measure, the sufficient statistics, and the **natural** parameter,  respectively.

The parameter space of `$\eta$` denoted by `$\Omega_\eta$` is determined so that the normalization constant is well-defined and (strictly) positive.

**Regular** natural parametrization `$\eta$`: parameter space `$\Omega_\eta$` is relatively open.

 In this post, we only consider
regular natural parametrizations since commonly used expoential family distributions have a regular natural parametrization.

This natural parametrization is special since the inner product `$\langle \mathbf{\eta} , \mathbf{T}_\eta(\mathbf{w}) \rangle$` is **linear** in `$\eta$`. As we will discuss later,  this linearity is essential.


* The base measure and the log-partition function are only unique up to a constant as illustrated by the following example. 
    >
>Example: Univariate Gaussian as an expoential family:
>
> Recall that in [Part I]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations-for-parametric-families), we consider this family as
>`$ \{ \mathcal{N}(w |\mu,\sigma) \Big| \mu \in \mathcal{R}, \sigma>0 \}$`, where `$\mathcal{N}(w |\mu,\sigma) = \frac{1}{\sqrt{2\pi \sigma} } \exp [- \frac{(w-\mu)^2}{2\sigma} ] $`.
>
> We re-express it in an expoential form as
>
>`$$
>\begin{aligned}
>p({w}|\mathbf{\eta})  &= \frac{1}{\sqrt{2\pi \sigma} } \exp [- \frac{(w-\mu)^2}{2\sigma} ] \\
>&= \underbrace{ \exp(0) }_{  h_\eta({w}) }  \exp( \langle \underbrace{\begin{bmatrix} -\frac{1}{2\sigma} \\ \frac{\mu}{\sigma}  \end{bmatrix}}_{\mathbf{\eta} }  ,  \underbrace{\begin{bmatrix} w^2 \\ w  \end{bmatrix}}_{ \mathbf{T}_\eta ({w}) } \rangle  -   \frac{1}{2} [ \log ( 2\pi ) + \log \sigma + \frac{\mu^2}{\sigma} ]     )   \\
>\end{aligned}
>$$`
> Since `$\sigma= -\frac{1}{2\eta_1} $` and `$\mu = -\frac{\eta_2}{2\eta_1}$`,  `$A_\eta(\mathbf{\eta}) = \frac{1} {2} [ \log ( 2\pi ) + \log \sigma + \frac{\mu^2}{\sigma} ] = \frac{1}{2} [ \log ( 2\pi ) + \log (-\frac{1}{2\eta_1})-\frac{\eta_2^2}{2\eta_1} ] $`.
>
> It is also valid that $ h_\eta({w}) = \frac{1}{\sqrt{2\pi}} $ and 
> `$A_\eta(\mathbf{\eta}) =  \frac{1}{2} [  \log (-\frac{1}{2\eta_1})-\frac{\eta_2^2}{2\eta_1} ] $`.
>
> We easily to verify that parameter space `$\Omega_\eta= \{ (\eta_1,\eta_2) | \eta_1<0 , \eta_2 \in \mathcal{R} \}$` is open in $\mathcal{R}^2$.

* The log-partition function could be differentiable w.r.t. `$\eta$` even when `$\mathbf{w}$` is discrete.
    >
>Example: Bernoulli family as an expoential family:
>
> Recall that in [Part I]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations-for-parametric-families), we consider this family as
>  `$ \{ \mathcal{I}(w=0) \pi + \mathcal{I}(w=1) (1-\pi) \Big| 0<\pi<1 \}$`
>
> We re-express it in an expoential form as
>
>`$$
>\begin{aligned}
>p({w}|\mathbf{\eta})
>&=  \mathcal{I}(w=0) \pi + \mathcal{I}(w=1) (1-\pi) \\
>&=\underbrace{ \exp(0) }_{  h_\eta({w}) }  \exp( \langle \underbrace{ \log \frac{\pi}{1-\pi}}_{\eta} , \underbrace{ \mathcal{I}(w=0)}_{T_\eta(w) } \rangle - \log \frac{1}{1-\pi} )
>\end{aligned}
>$$`
> Since `$\pi = \frac{\exp(\eta)}{1+ \exp(\eta) } $` , we have `$A_\eta(\mathbf{\eta}) =  \log \frac{1}{1-\pi} = \log(1+\exp(\eta))$`. <br />
> We easily to verify that parameter space `$\Omega_\eta= \{ \eta | \eta \in \mathcal{R} \}$` is open in $\mathcal{R}$.

* A natural parametrization is only unique up to an invertiable linear transformation.
    This is one of the reasons using natural-gradient descent since it is linearly invariant.
    >
> For simplicity, let's assume set `$\Omega_\lambda := \{ \mathbf{U}^{-1} \eta | \eta \in \Omega_\eta \} = \Omega_\eta$`, where `$\mathbf{U}$` is a constant invertiable matrix. 
>
>Consider a linear reparametrization such as `$\lambda=\mathbf{U}^{-1} \mathbf{\eta}$`, parametrization `$\lambda$` is also a natural parametrization as
>`$$
>\begin{aligned}
>p(\mathbf{w}|\mathbf{\lambda})
>&= h_\eta(\mathbf{w}) \exp( \langle \mathbf{U}\mathbf{\lambda} , \mathbf{T}_\eta(\mathbf{w}) \rangle - A_\eta( \mathbf{U}\mathbf{\lambda}) ) \\
>&=  h_\eta(\mathbf{w})\exp( \langle \mathbf{\lambda} , \mathbf{U}^T \mathbf{T}_\eta(\mathbf{w}) \rangle - A_\eta(\mathbf{U}\mathbf{\lambda}) ) \\
>&= h_\lambda(\mathbf{w})  \exp( \langle \mathbf{\lambda} ,  \mathbf{T}_\lambda(\mathbf{w}) \rangle - A_\lambda(\mathbf{\lambda}) ) 
>\end{aligned}
>$$` where `$h_\lambda(\mathbf{w}):= h_\eta(\mathbf{w})$`,  `$\mathbf{T}_\lambda(\mathbf{w}):= \mathbf{U}^T\mathbf{T}_\eta(\mathbf{w})$`, and 
>`$A_\lambda(\mathbf{\lambda}):= A_\eta(\mathbf{U}\mathbf{\lambda})$`.




## Minimal Parametrizations of Exponential Family

Now, we discuss particular parametrizations of an expoential family.

 **Minimal** natural parametrization: the corresponding sufficient stattistics `$\mathcal{T}(\mathbf{w})$` is linearly independent.


A regular, minimal, and natural parametrization `$\eta$` has many nice properties.

* It is an intrinstic parametrization as we discussed in
 [Part I]({{ site.baseurl }}{% post_url 2021-09-06-Geomopt01 %}#intrinsic-parameterizations-for-parametric-families).

* The parameter space `$\Omega_\eta$` is open in `$\mathcal{R}^K$`, where
`$K$` is the number of entires of this parameter array.

* The log-partition function `$A_\eta(\eta)$` is  infinitely differentiable and strictly convex in `$\Omega_\eta$`.

* The FIM `$\mathbf{F}_\eta(\eta) = \nabla_\eta^2 A_\eta(\eta)$` is positive-definite.

We will only show the first property in this post. The remaining properties can be found in the literature.
Note that the linearity in the inner product `$\langle \mathbf{\eta} , \mathbf{T}_\eta(\mathbf{w}) \rangle$`,  plays a key role in showing these properties.


Recall that a parametrization is intrinstic if 
 partial derivatives 
`$ \{ \partial_{\eta_i} \log p(\mathbf{w}|\eta) \} $`  are linearly independent.
Since the parameter space is open in `$\mathcal{R}^K$` and the log-partition function `$A_\eta(\eta)$` differentiable, we know that these partial derivatives  as
`$$
\begin{aligned}
\partial_{\eta_i} \log p(\mathbf{w}|\eta) = \langle \mathbf{e}_i,  \mathbf{T} (\mathbf{w}) \rangle - \partial_{\eta_i}A_\eta(\eta) 
\end{aligned}
$$` where `$\mathbf{e}_i$` is an one-hot array which has zero in all entries except the $i$-th entry.

> Proof by contradiction:
>
>If these partial derivatives are linearly dependent, there exist a set of non-zero constant `$c_i$` such that
>`$\sum_i c_i \partial_{\eta_i} \log p(\mathbf{w}|\eta)= 0 $`, where the value of `$c_i$` does not depent on  `$\mathbf{w}$`.
>`$$
>\begin{aligned}
>0 &= \sum_{i=1}^{K} c_i \partial_{\eta_i} \log p(\mathbf{w}|\eta) \\
>&= \sum_{i=1}^{K} c_i \langle \mathbf{e}_i,  \mathbf{T} (\mathbf{w}) \rangle -   c_i\partial_{\eta_i}A_\eta(\eta) \\
>\end{aligned}
>$$`
>
>Since  `$c_i$` is a non-zero constant and its value does not depent on  `$\mathbf{w}$`, we must have
> `$$
>\begin{aligned}
> 0 =\sum_{i=1}^{K} c_i \langle \mathbf{e}_i,  \mathbf{T} (\mathbf{w}) \rangle ,
>\end{aligned}
> $$` which implies that
>the sufficient stattistics `$\mathcal{T}(\mathbf{w})$` is linearly dependent. This is a contradiction since `$\eta$` is a minimal natural parametrization.

Now, we give an example of a minimal natural parametrization.

>Example: Minimal parametrization for multivate Gaussians
>
>Consider a $d$-dimensional Gaussian family
>We specify an intrinsic parameterization $\mathbf{\tau}$ of the  family as `$ \{ \mathcal{N}(\mathbf{w} |\mathbf{\mu},\mathbf{\Sigma}) \Big| \mathbf{\mu} \in \mathcal{R}^d, \mathbf{\Sigma}   \succ \mathbf{0} \}$`
>
> We re-express it in an expoential form as
>
>`$$
>\begin{aligned}
>p({w}|\mathbf{\lambda})  &= \frac{1}{\sqrt{ \mathrm{det}( 2\pi \Sigma )} } \exp [- \frac{1}{2} (\mathbf{w}-\mathbf{\mu})^T \Sigma^{-1} (\mathbf{w}-\mathbf{\mu})  ] \\
>&= \underbrace{ \exp(0) }_{  h_\lambda({w}) }  \exp( \langle \underbrace{\begin{bmatrix} -\frac{1}{2} \mathrm{vec}( \Sigma^{-1} ) \\ \Sigma^{-1}\mu  \end{bmatrix}}_{\mathbf{\lambda} }  ,  \underbrace{\begin{bmatrix} \mathrm{vec}( \mathbf{w} \mathbf{w}^T) \\ \mathbf{w}  \end{bmatrix}}_{ \mathbf{T}_\lambda ({w}) } \rangle  -   \frac{1}{2} [ d\log ( 2\pi ) + \log \mathrm{det} (\Sigma) + \mu^T \Sigma^{-1} \mu ]     )   \\
>\end{aligned}
>$$` where `$\mathrm{vec}()$` is the vectorization function
>and  `$\lambda$` is a $(d+d^2)$-dim array.
>
> Parametrization $\lambda$ is a natural and regular parametrization. However, it is NOT a minimal
>parametrization since `$\mathbf{w} \mathbf{w}^T$` is symmetric and therefore the sufficient statistics is linearly dependent.
>
> A minimal natural parametrization $\eta$ should be
>`$$
>\begin{aligned}
>p({w}|\mathbf{\eta})
>&= \underbrace{ \exp(0) }_{  h_\eta({w}) }  \exp( \langle \underbrace{\begin{bmatrix} -\frac{1}{2} \mathrm{vech}( \Sigma^{-1} ) \\ \Sigma^{-1}\mu  \end{bmatrix}}_{\mathbf{\eta} }  ,  \underbrace{\begin{bmatrix} \mathrm{vech}( \mathbf{w} \mathbf{w}^T) \\ \mathbf{w}  \end{bmatrix}}_{ \mathbf{T}_\eta ({w}) } \rangle  -   \frac{1}{2} [ d\log ( 2\pi ) + \log \mathrm{det} (\Sigma) + \mu^T \Sigma^{-1} \mu ]     )   \\
>\end{aligned}
>$$` where `$\mathrm{vech}()$` is the [half-vectorization function](https://en.wikipedia.org/wiki/Vectorization_(mathematics)#Half-vectorization) 
>and  `$\eta$` is a $(d+\frac{d(d+1)}{2})$-dim array.
>
> As we discussed in [Part II]({{ site.baseurl }}{% post_url 2021-10-04-Geomopt02 %}#riemannian-steepest-direction),  `$\eta$` is an intrinstic parameterization while `$\lambda$` is not.




## Efficient Natural-gradient Computation


## Natural-gradient Descent as Unconstrained Mirror Descent


# Handling Parameter Constraints
------

## Using an Adaptive Step-size

## Projected Natural-gradient Descent and (Constrained) Mirror Descent

## Riemannian Gradient Descent


